# 目录
  - [1.有哪些方法能提升CNN模型的泛化能力](#user-content-1有哪些方法能提升cnn模型的泛化能力)
  - [2.BN层面试高频问题大汇总](#user-content-2bn层面试高频问题大汇总)
  - [3.Instance Normalization的作用](#user-content-3instance-normalization的作用)
  - [4.有哪些提高GAN训练稳定性的Tricks](#user-content-4有哪些提高gan训练稳定性的tricks)
    - [1.输入Normalize](#user-content-1输入normalize)
    - [2.替换原始的GAN损失函数和标签反转](#user-content-2替换原始的gan损失函数和标签反转)
    - [3.使用具有球形结构的随机噪声$Z$作为输入](#user-content-3使用具有球形结构的随机噪声z作为输入)
    - [4.使用BatchNorm](#user-content-4使用batchnorm)
    - [5.避免使用ReLU，MaxPool等操作引入稀疏梯度](#user-content-5避免使用relu，maxpool等操作引入稀疏梯度)
    - [6.使用Soft和Noisy的标签](#user-content-6使用soft和noisy的标签)
    - [7.使用Adam优化器](#user-content-7使用adam优化器)
    - [8.追踪训练失败的信号](#user-content-8追踪训练失败的信号)
    - [9.在输入端适当添加噪声](#user-content-9在输入端适当添加噪声)
    - [10.生成器和判别器差异化训练](#user-content-10生成器和判别器差异化训练)
    - [11.Two Timescale Update Rule (TTUR)](#user-content-11two-timescale-update-rule-ttur)
    - [12.Gradient Penalty （梯度惩罚）](#user-content-12gradient-penalty-（梯度惩罚）)
    - [13.Spectral Normalization（谱归一化）](#user-content-13spectral-normalization（谱归一化）)
    - [14.使用多个GAN结构](#user-content-14使用多个gan结构)
  - [5.什么是超参数？有哪些常用的超参数？](#user-content-5什么是超参数？有哪些常用的超参数？)
  - [6.如何寻找到最优超参数？](#user-content-6如何寻找到最优超参数？)
  - [7.Spectral Normalization的相关知识](#user-content-7spectral-normalization的相关知识)
  - [8.什么是EMA?](#8.什么是EMA?)
  - [9.深度学习中有哪些经典的优化器？](#user-content-9深度学习中有哪些经典的优化器？)
  - [10.深度学习中常用的学习率衰减策略有哪些？](#user-content-10深度学习中常用的学习率衰减策略有哪些？)
  - [11.什么是方向导数？](#user-content-11什么是方向导数?)
  - [12.什么是梯度](#user-content-12什么是梯度？)
  - [13.为什么沿梯度方向是函数变化最快的方向？](#user-content-13为什么沿梯度方向是函数变化最快的方向？)

<h2 id="1有哪些方法能提升cnn模型的泛化能力">1.有哪些方法能提升CNN模型的泛化能力</h2>

1. 采集更多数据：数据决定算法的上限。

2. 优化数据分布：数据类别均衡。

3. 选用合适的目标函数。

4. 设计合适的网络结构。

5. 数据增强。

6. 权值正则化。

7. 使用合适的优化器等。


<h2 id="2bn层面试高频问题大汇总">2.BN层面试高频问题大汇总</h2>

<font color=DeepSkyBlue>BN层解决了什么问题？</font>

统计机器学习中的一个经典假设是“源空间（source domain）和目标空间（target domain）的数据分布（distribution）是一致的”。如果不一致，那么就出现了新的机器学习问题，如transfer learning/domain adaptation等。而covariate shift就是分布不一致假设之下的一个分支问题，它是指源空间和目标空间的条件概率是一致的，但是其边缘概率不同。对于神经网络的各层输出，由于它们经过了层内卷积操作，其分布显然与各层对应的输入信号分布不同，而且差异会随着网络深度增大而增大，但是它们所能代表的label仍然是不变的，这便符合了covariate shift的定义。

因为神经网络在做非线性变换前的激活输入值随着网络深度加深，其分布逐渐发生偏移或者变动（即上述的covariate shift）。之所以训练收敛慢，一般是整体分布逐渐往非线性函数的取值区间的上下限两端靠近（比如sigmoid），所以这导致反向传播时低层神经网络的梯度消失，这是训练深层神经网络收敛越来越慢的本质原因。而BN就是通过一定的正则化手段，把每层神经网络任意神经元这个输入值的分布强行拉回到均值为0方差为1的标准正态分布，避免因为激活函数导致的梯度弥散问题。所以与其说BN的作用是缓解covariate shift，也可以说BN可缓解梯度弥散问题。

<font color=DeepSkyBlue>BN的公式</font>

![](https://files.mdnice.com/user/33499/41b0c64d-97db-4ca7-b116-3f4b5402f48f.png)

其中scale和shift是两个可学的参数，因为减去均值除方差未必是最好的分布。比如数据本身就很不对称，或者激活函数未必是对方差为1的数据有最好的效果。所以要加入缩放及平移变量来完善数据分布以达到比较好的效果。

<font color=DeepSkyBlue>BN层训练和测试的不同</font>

在训练阶段，BN层是对每个batch的训练数据进行标准化，即用每一批数据的均值和方差。（每一批数据的方差和标准差不同）

而在测试阶段，我们一般只输入一个测试样本，并没有batch的概念。因此这个时候用的均值和方差是整个数据集训练后的均值和方差，可以通过滑动平均法求得：

![](https://files.mdnice.com/user/33499/a1659e39-7ce1-484c-9b65-a777814b23ae.png)

上面式子简单理解就是：对于均值来说直接计算所有batch $u$ 值的平均值；然后对于标准偏差采用每个batch $σ_B$ 的无偏估计。

在测试时，BN使用的公式是：
  
![](https://files.mdnice.com/user/33499/e21b91a4-63f5-4259-b9e2-55fdf337e111.png)

<font color=DeepSkyBlue>BN训练时为什么不用整个训练集的均值和方差？</font>
  
因为用整个训练集的均值和方差容易过拟合，对于BN，其实就是对每一batch数据标准化到一个相同的分布，而不同batch数据的均值和方差会有一定的差别，而不是固定的值，这个差别能够增加模型的鲁棒性，也会在一定程度上减少过拟合。

<font color=DeepSkyBlue>BN层用在哪里？</font>
  
在CNN中，BN层应该用在非线性激活函数前面。由于神经网络隐藏层的输入是上一层非线性激活函数的输出，在训练初期其分布还在剧烈改变，此时约束其一阶矩和二阶矩无法很好地缓解 Covariate Shift；而BN的分布更接近正态分布，限制其一阶矩和二阶矩能使输入到激活函数的值分布更加稳定。

<font color=DeepSkyBlue>BN层的参数量</font>
  
我们知道 $γ$ 和 $β$ 是需要学习的参数，而BN的本质就是利用优化学习改变方差和均值的大小。在CNN中，因为网络的特征是对应到一整张特征图上的，所以做BN的时候也是以特征图为单位而不是按照各个维度。比如在某一层，特征图数量为 $c$ ，那么做BN的参数量为 $c * 2$ 。

<font color=DeepSkyBlue>BN的优缺点</font>

**优点：**

1. 可以选择较大的初始学习率。因为这个算法收敛很快。

2. 可以不用dropout，L2正则化。

3. 不需要使用局部响应归一化。
 
4. 可以把数据集彻底打乱。

5. 模型更加健壮。

**缺点：**

1. Batch Normalization非常依赖Batch的大小，当Batch值很小时，计算的均值和方差不稳定。

2. 所以BN不适用于以下几个场景：小Batch，RNN等。


<h2 id="3instance-normalization的作用">3.Instance Normalization的作用</h2>

Instance Normalization（IN）和Batch Normalization（BN）一样，也是Normalization的一种方法，<font color=DeepSkyBlue>只是IN是作用于单张图片，而BN作用于一个Batch</font>。

BN对Batch中的每一张图片的同一个通道一起进行Normalization操作，而IN是指单张图片的单个通道单独进行Normalization操作。如下图所示，其中C代表通道数，N代表图片数量（Batch）。

![](https://img-blog.csdnimg.cn/20201127225740900.png)

IN适用于生成模型中，比如图片风格迁移。因为图片生成的结果主要依赖于某个图像实例，所以对整个Batch进行Normalization操作并不适合图像风格化的任务，在风格迁移中使用IN不仅可以加速模型收敛，并且可以保持每个图像实例之间的独立性。

下面是IN的公式：

![](https://img-blog.csdnimg.cn/20201127231032309.png)

其中t代表图片的index，i代表的是feature map的index。

<h2 id="4有哪些提高gan训练稳定性的tricks">4.有哪些提高GAN训练稳定性的Tricks</h2>

<h3 id="1输入normalize">1.输入Normalize</h3>

 1. 将输入图片Normalize到	$[-1，1]$ 之间。
 2. 生成器最后一层的输出使用Tanh激活函数。

Normalize非常重要，没有处理过的图片是没办法收敛的。图片Normalize一种简单的方法是（images-127.5）/127.5，然后送到判别器去训练。同理生成的图片也要经过判别器，即生成器的输出也是-1到1之间，所以使用Tanh激活函数更加合适。

<h3 id="2替换原始的gan损失函数和标签反转">2.替换原始的GAN损失函数和标签反转</h3>

1. 原始GAN损失函数会出现训练早期梯度消失和Mode collapse（模型崩溃）问题。可以使用Earth Mover distance（推土机距离）来优化。

2. 实际工程中用反转标签来训练生成器更加方便，即把生成的图片当成real的标签来训练，把真实的图片当成fake来训练。

<h3 id="3使用具有球形结构的随机噪声z作为输入">3.使用具有球形结构的随机噪声 $Z$ 作为输入</h3>

1. 不要使用均匀分布进行采样

![](https://img-blog.csdnimg.cn/202003111920127.png)

2. 使用高斯分布进行采样
![](https://img-blog.csdnimg.cn/20200311192036539.png)

<h3 id="4使用batchnorm">4.使用BatchNorm</h3>

1. 一个mini-batch中必须只有real数据或者fake数据，不要把他们混在一起训练。
2. 如果能用BatchNorm就用BatchNorm，如果不能用则用instance normalization。

![](https://img-blog.csdnimg.cn/20200311192617441.png)

<h3 id="5避免使用relu，maxpool等操作引入稀疏梯度">5.避免使用ReLU，MaxPool等操作引入稀疏梯度</h3>

1. GAN的稳定性会因为引入稀疏梯度受到很大影响。
2. 最好使用类LeakyReLU的激活函数。（D和G中都使用）
3. 对于下采样，最好使用：Average Pooling或者卷积+stride。
4. 对于上采样，最好使用：PixelShuffle或者转置卷积+stride。

最好去掉整个Pooling逻辑，因为使用Pooling会损失信息，这对于GAN训练没有益处。

<h3 id="6使用soft和noisy的标签">6.使用Soft和Noisy的标签</h3>

1. Soft Label，即使用 $[0.7-1.2]$ 和 $[0-0.3]$ 两个区间的随机值来代替正样本和负样本的Hard Label。
2. 可以在训练时对标签加一些噪声，比如随机翻转部分样本的标签。

<h3 id="7使用adam优化器">7.使用Adam优化器</h3>

1. Adam优化器对于GAN来说非常有用。
2. 在生成器中使用Adam，在判别器中使用SGD。

<h3 id="8追踪训练失败的信号">8.追踪训练失败的信号</h3>

1. 判别器的损失=0说明模型训练失败。
2. 如果生成器的损失稳步下降，说明判别器没有起作用。

<h3 id="9在输入端适当添加噪声">9.在输入端适当添加噪声</h3>

1. 在判别器的输入中加入一些人工噪声。
2. 在生成器的每层中都加入高斯噪声。

<h3 id="10生成器和判别器差异化训练">10.生成器和判别器差异化训练</h3>

1. 多训练判别器，尤其是加了噪声的时候。

<h3 id="11two-timescale-update-rule-ttur">11.Two Timescale Update Rule (TTUR)</h3>

对判别器和生成器使用不同的学习速度。使用较低的学习率更新生成器，判别器使用较高的学习率进行更新。

<h3 id="12gradient-penalty-（梯度惩罚）">12.Gradient Penalty （梯度惩罚）</h3>

使用梯度惩罚机制可以极大增强 GAN 的稳定性，尽可能减少mode collapse问题的产生。

<h3 id="13spectral-normalization（谱归一化）">13.Spectral Normalization（谱归一化）</h3>

Spectral normalization可以用在判别器的weight normalization技术，可以确保判别器是K-Lipschitz连续的。

<h3 id="14使用多个gan结构">14.使用多个GAN结构</h3>

可以使用多个GAN/多生成器/多判别器结构来让GAN训练更稳定，提升整体效果，解决更难的问题。

<h2 id="5什么是超参数？有哪些常用的超参数？">5.什么是超参数？有哪些常用的超参数？</h2>

### 什么是超参数？

在深度学习中，**超参数（Hyperparameters）是指在训练开始前设置的模型参数，不是通过训练学习得到的**。超参数的选择对模型性能有很大的影响，不同的超参数设置可能导致显著不同的训练结果。
 
### 常见的超参数包括：
1. **预处理（Data Augmentation、Normalization and Standardization）**：对输入数据进行预处理。
2. **批量大小（Batch Size）**：每次梯度更新使用的训练样本数量。
3. **学习率（Learning Rate）**：控制模型权重更新的步伐。
4. **学习率衰减（Learning Rate Decay）**：控制学习率随时间逐渐减小的方式。
5. **优化算法/优化器（Optimizer）**：如SGD、Adam、RMSprop等，控制模型权重的更新方式。
6. **损失函数（Loss Function）**：设置训练目标。
8. **迭代次数（Number of Epochs）**：训练过程中遍历整个训练集的次数。
9. **神经网络结构（Network Architecture）**：如层数、每层的神经元数量等。
10. **正则化参数（Regularization Parameters）**：如L2正则化系数、Dropout率等。
11. **激活函数（Activation Function）**：决定每个神经元的输出形式。
12. **权重初始化（Weight Initialization）**：决定模型的初始权重。

<h2 id="6如何寻找到最优超参数？">6.如何寻找到最优超参数？</h2>

**找到最优超参数的过程通常被称为超参数优化（Hyperparameter Optimization）**。常用的方法包括以下几种：

#### 1. **手动调整（Manual Tuning）**：
手动调整超参数是最简单但最费时的方法，通常依赖于经验和试错。可以通过观察模型在验证集上的性能来逐步调整超参数。

#### 2. **网格搜索（Grid Search）**：
网格搜索是一种系统的尝试多个超参数组合的方法。
- **步骤**：
  1. 定义每个超参数的可能取值范围。
  2. 穷举所有可能的超参数组合。
  3. 对每个组合进行交叉验证，评估模型在验证集上的性能。
  4. 选择性能最好的组合作为最优超参数。
- **缺点**：计算成本高，特别是超参数数量多和取值范围大的情况下。

#### 3. **随机搜索（Random Search）**：
随机搜索是一种在超参数空间中随机采样进行尝试的方法。
- **步骤**：
  1. 定义每个超参数的可能取值范围。
  2. 随机采样一定数量的超参数组合。
  3. 对每个组合进行交叉验证，评估模型在验证集上的性能。
  4. 选择性能最好的组合作为最优超参数。
- **优点**：比网格搜索更有效率，通常在相同计算成本下能找到更好的超参数组合。

#### 4. **贝叶斯优化（Bayesian Optimization）**：
贝叶斯优化是一种利用贝叶斯统计理论的方法，通过构建超参数与模型性能之间的概率模型来选择最优超参数。
- **步骤**：
  1. 选择初始点，训练模型并评估性能。
  2. 构建代理模型（通常是高斯过程）来模拟超参数空间。
  3. 使用代理模型选择下一个最有可能提升性能的超参数组合。
  4. 训练模型并更新代理模型。
  5. 重复步骤3和4，直到达到预定的迭代次数或时间限制。
- **优点**：比随机搜索和网格搜索更高效，适合高维和复杂的超参数空间。

#### 5. **遗传算法（Genetic Algorithms）**：
遗传算法是一种基于生物进化原理的优化算法。
- **步骤**：
  1. 初始化一个包含多个超参数组合的种群。
  2. 通过交叉和变异生成新的超参数组合。
  3. 根据模型性能评估每个组合的适应度，选择适应度高的组合进行下一代繁衍。
  4. 重复步骤2和3，直到达到预定的迭代次数或性能。
- **优点**：能探索复杂的超参数空间，适合解决多峰优化问题。

#### 6. **超参数调优库**：
一些开源的超参数调优库提供了自动化的超参数优化功能。
- **常见库**：
  - **Hyperopt**：支持贝叶斯优化，基于TPE（Tree of Parzen Estimators）。
  - **Optuna**：灵活且高效的超参数优化库，支持贝叶斯优化、随机搜索和其他自定义优化算法。
  - **Ray Tune**：支持多种搜索算法和分布式超参数优化。
  - **Scikit-Optimize**：基于Scikit-Learn的优化库，支持贝叶斯优化。

### 示例：使用Optuna进行超参数优化

以下是使用Optuna进行超参数优化的简单示例：

```python
import optuna
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# 加载数据集
iris = load_iris()
X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)

# 定义目标函数
def objective(trial):
    # 定义超参数的搜索空间
    C = trial.suggest_loguniform('C', 1e-5, 1e2)
    gamma = trial.suggest_loguniform('gamma', 1e-5, 1e-1)
    
    # 创建模型
    model = SVC(C=C, gamma=gamma)
    
    # 训练模型
    model.fit(X_train, y_train)
    
    # 评估模型
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    
    return accuracy

# 创建Optuna研究对象并进行优化
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=100)

# 输出最优超参数
print('Best trial:')
trial = study.best_trial
print(f'  Accuracy: {trial.value}')
print('  Params: ')
for key, value in trial.params.items():
    print(f'    {key}: {value}')
```

通过这种方法，可以高效地寻找最优超参数组合，从而提升模型性能。

<h2 id="7spectral-normalization的相关知识">7.Spectral Normalization的相关知识</h2>

Spectral Normalization是一种wegiht Normalization技术，和weight-clipping以及gradient penalty一样，也是让模型满足1-Lipschitz条件的方式之一。

<font color=DeepSkyBlue>Lipschitz（利普希茨）条件限制了函数变化的剧烈程度，即函数的梯度，来确保统计的有界性。因此函数更加平滑，在神经网络的优化过程中，参数变化也会更稳定，不容易出现梯度爆炸</font>。

Lipschitz条件的约束如下所示：

<img width="264" alt="截屏2023-11-13 20 35 07" src="https://github.com/WeThinkIn/Interview-for-Algorithm-Engineer/assets/48612300/56926564-0756-4910-bbd1-cd8b2e277ff4">

其中 $K$ 代表一个常数，即利普希茨常数。若 $K=1$ ，则是1-Lipschitz。

在GAN领域，Spectral Normalization有很多应用。在WGAN中，只有满足1-Lipschitz约束时，W距离才能转换成较好求解的对偶问题，使得WGAN更加从容的训练。

如果想让矩阵A映射： $R^{n}\to R^{m}$ 满足K-Lipschitz连续，K的最小值为 $\sqrt{\lambda_{1}}$ ( $\lambda_{1}$ 是 $A_TA$ 的最大特征值)，那么要想让矩阵A满足1-Lipschitz连续，只需要在A的所有元素上同时除以 $\sqrt{\lambda_{1}}$ （Spectral norm）。

<font color=DeepSkyBlue>Spectral Normalization实际上在做的事，是将每层的参数矩阵除以自身的最大奇异值，本质上是一个逐层SVD的过程，但是真的去做SVD就太耗时了，所以采用幂迭代的方法求解</font>。过程如下图所示：

![幂迭代法流程](https://files.mdnice.com/user/33499/450732f1-84ad-4bef-a079-d15bb4c8646d.png)

得到谱范数 $\sigma_l(W)$ 后，每个参数矩阵上的参数皆除以它，以达到Normalization的目的。


<h2 id="8.什么是EMA?">8.什么是EMA?</h2>

EMA（指数移动平均，Exponential Moving Average）是一种在深度学习和统计领域常用的技术，特别是在参数优化和数据平滑处理中非常有用。在深度学习中，EMA 常用于模型训练过程中参数的更新，以帮助提高模型的稳定性和性能。

### EMA 的工作原理

EMA 的核心思想是对数据或参数进行加权平均，其中较新的观测值会被赋予更高的权重。这种方法可以快速反映最近的变化，同时还能保留一部分之前的信息，从而在保持数据平滑的同时减少噪声的影响。即将每次梯度更新后的权值和前一次的权重进行联系，使得本次更新收到上次权值的影响。

公式表示为：

$$EMA_t = \alpha \times x_t + (1 - \alpha) \times EMA_{t-1}$$

其中：
- $EMA_t$ 是在时间点 t 的 EMA 值。
- $x_t$ 是在时间点 t 的观测值。
- $\alpha$ 是平滑因子，通常在 0 和 1 之间。

### EMA 在深度学习中的应用

在深度学习中，EMA 可用于模型参数的更新。例如，在训练一个深度神经网络时，通过计算参数的 EMA 可以得到更稳定的模型版本。这在训练过程中尤其有用，因为它可以减少参数更新中的高频波动，从而帮助模型更好地收敛。

### 优势

使用 EMA 更新模型参数的优势包括：
- **减少过拟合**：EMA 可以平滑模型在训练过程中的表现，避免过度追踪训练数据中的噪声。
- **增强泛化能力**：通过平滑化参数更新，模型在未见数据上的表现往往更加稳定和强健。

ema版本的模型可以生成更多创意性的结果，适合训练使用


<h1 id="9深度学习中有哪些经典的优化器？">9.深度学习中有哪些经典的优化器？</h1>

### SGD（随机梯度下降）

随机梯度下降的优化算法在科研和工业界是很常用的。

<font color=DeepSkyBlue>很多理论和工程问题都能转化成对目标函数进行最小化的数学问题。</font>

举个例子：梯度下降（Gradient Descent）就好比一个人想从高山上奔跑到山谷最低点，用最快的方式奔向最低的位置。

SGD的公式：

![](https://img-blog.csdnimg.cn/20200802220806705.png#pic_center)

动量（Momentum）公式：

![](https://img-blog.csdnimg.cn/20200802220955480.png#pic_center)

基本的mini-batch SGD优化算法在深度学习取得很多不错的成绩。然而也存在一些问题需解决：

1. 选择恰当的初始学习率很困难。
2. 学习率调整策略受限于预先指定的调整规则。
3. 相同的学习率被应用于各个参数。
4. 高度非凸的误差函数的优化过程，如何避免陷入大量的局部次优解或鞍点。

### AdaGrad（自适应梯度）

AdaGrad优化算法（Adaptive Gradient，自适应梯度），它能够对每个不同的参数调整不同的学习率，对频繁变化的参数以更小的步长进行更新，而稀疏的参数以更大的步长进行更新。

AdaGrad公式：

![](https://img-blog.csdnimg.cn/20200802222758468.png#pic_center)

![](https://img-blog.csdnimg.cn/20200802222812287.png#pic_center)


$g_{t,i}$ 表示t时刻的 $\theta_{i}$ 梯度。

$G_{t,ii}$ 表示t时刻参数 $\theta_{i}$ 的梯度平方和。

与SGD的核心区别在于计算更新步长时，增加了分母：<font color=DeepSkyBlue>梯度平方累积和的平方根</font>。此项能够累积各个参数 $\theta_{i}$ 的历史梯度平方，频繁更新的梯度，则累积的分母逐渐偏大，那么更新的步长相对就会变小，而稀疏的梯度，则导致累积的分母项中对应值比较小，那么更新的步长则相对比较大。

AdaGrad能够自动为不同参数适应不同的学习率（平方根的分母项相当于对学习率α进进行了自动调整，然后再乘以本次梯度），大多数的框架实现采用默认学习率α=0.01即可完成比较好的收敛。

**优势：** 在数据分布稀疏的场景，能更好利用稀疏梯度的信息，比标准的SGD算法更有效地收敛。

**缺点：** 主要缺陷来自分母项的对梯度平方不断累积，随时间的增加，分母项越来越大，最终导致学习率收缩到太小无法进行有效更新。

### RMSProp
RMSProp结合梯度平方的指数移动平均数来调节学习率的变化。能够在不稳定的目标函数情况下进行很好地收敛。

计算t时刻的梯度：

![](https://img-blog.csdnimg.cn/20200802224130311.png#pic_center)

计算梯度平方的指数移动平均数（Exponential Moving Average）， $\gamma$ 是遗忘因子（或称为指数衰减率），依据经验，默认设置为0.9。

![](https://img-blog.csdnimg.cn/20200802224414890.png#pic_center)

梯度更新的时候，与AdaGrad类似，只是更新的梯度平方的期望（指数移动均值），其中 $\varepsilon = 10^{-8}$ ，避免除数为0。默认学习率 $\alpha = 0.001$ 。

![](https://img-blog.csdnimg.cn/20200802224711856.png#pic_center)

**优势：** 能够克服AdaGrad梯度急剧减小的问题，在很多应用中都展示出优秀的学习率自适应能力。尤其在不稳定(Non-Stationary)的目标函数下，比基本的SGD、Momentum、AdaGrad表现更良好。

### Adam

Adam优化器结合了AdaGrad和RMSProp两种优化算法的优点。对梯度的一阶矩估计（First Moment Estimation，即梯度的均值）和二阶矩估计（Second Moment Estimation，即梯度的未中心化的方差）进行综合考虑，计算出更新步长。

**Adam的优势：**

1. 实现简单，计算高效，对内存需求少。
2. 参数的更新不受梯度的伸缩变换影响。
3. 超参数具有很好的解释性，且通常无需调整或仅需很少的微调。
4. 更新的步长能够被限制在大致的范围内（初始学习率）。
5. 能自然地实现步长退火过程（自动调整学习率）。
6. 很适合应用于大规模的数据及参数的场景。
7. 适用于不稳定目标函数。
8. 适用于梯度稀疏或梯度存在很大噪声的问题。

**Adam的实现原理：**

![](https://img-blog.csdnimg.cn/20200802230838428.png)

计算t时刻的梯度：

![](https://img-blog.csdnimg.cn/20200802230926200.png#pic_center)

然后计算梯度的指数移动平均数， $m_{0}$ 初始化为0。

类似于Momentum算法，综合考虑之前累积的梯度动量。

$\beta_{1}$ 系数为指数衰减率，控制动量和当前梯度的权重分配，通常取接近于1的值。默认为0.9。

![](https://img-blog.csdnimg.cn/20200802232541831.png#pic_center)

接着，计算梯度平方的指数移动平均数， $v_{0}$ 初始化为0。

$\beta_{2}$ 系数为指数衰减率，控制之前的梯度平方的影响情况。默认为0.999。

类似于RMSProp算法，对梯度平方进行加权均值。

![](https://img-blog.csdnimg.cn/20200802233221851.png#pic_center)

由于 $m_{0}$ 初始化为0，会导致$m_{t}$偏向于0，尤其在训练初期阶段。

所以，此处需要对梯度均值$m_{t}$进行偏差纠正，降低偏差对训练初期的影响。

![](https://img-blog.csdnimg.cn/2020080223350261.png#pic_center)

同时 $v_{0}$ 也要进行偏差纠正：

![](https://img-blog.csdnimg.cn/20200802233536671.png#pic_center)

最后总的公式如下所示：

![](https://img-blog.csdnimg.cn/20200802233611955.png#pic_center)

其中默认学习率 $\alpha = 0.001$ ， $\varepsilon = 10^{-8}$ 避免除数变为0。

从表达式中可以看出，对更新的步长计算，能够从梯度均值和梯度平方两个角度进行自适应地调节，而不是直接由当前梯度决定。

**Adam的不足：**

虽然Adam算法目前成为主流的优化算法，不过在很多领域里（如计算机视觉的图像识别、NLP中的机器翻译）的最佳成果仍然是使用带动量（Momentum）的SGD来获取到的。

<h1 id="10深度学习中常用的学习率衰减策略有哪些？">10.深度学习中常用的学习率衰减策略有哪些？</h1>

在AI领域中，合适的学习率调整策略对于模型的训练效果和收敛速度至关重要。

学习率衰减（或调整）是用来在训练过程中逐步减小学习率的方法，目的是帮助模型更好地收敛，避免训练过程中的振荡或不稳定。

以下是几种常用的学习率衰减方法：

### 1. 固定学习率衰减
这是最简单的衰减方法之一，其中学习率按预定的固定间隔和固定因子进行减少。例如，每过10个epoch将学习率乘以0.1。

### 2. 指数衰减
在指数衰减模式下，学习率按照指数函数逐步减小，通常定义为：
$\text{Learning Rate} = \text{Initial Learning Rate} \times e^{-\text{decay rate} \times \text{epoch}}$
其中，decay rate是一个预先设定的常数，epoch是当前的训练轮数。

### 3. 时间基衰减
时间基衰减与指数衰减类似，但学习率的衰减与训练的具体时间（通常是epoch数）更直接相关：
$\text{Learning Rate} = \frac{\text{Initial Learning Rate}}{1 + \text{decay rate} \times \text{epoch}}$

### 4. 阶梯衰减
在阶梯衰减中，学习率在一系列预设的epoch（如每20个epoch）后显著下降。这种衰减通常是手动设置的，非常直观，允许模型在较高的学习率下快速学习，并在训练后期通过较低的学习率细化模型。

### 5. 余弦衰减
余弦衰减是一种较新的策略，它模仿了余弦函数的形状来调整学习率，从初始学习率逐渐减小到接近零的值。这种方法在一些周期性或重启的训练策略中特别有效，可以帮助模型跳出局部最小值。

### 6. 适应性学习率方法
这包括像Adam和RMSprop这样的优化算法，这些算法本身就能够调整每个参数的学习率，通常基于历史梯度的平方（用于归一化梯度）。这些方法自动调整学习率，无需显式的衰减策略。

### 7. 热身和重启
- **学习率热身**：在训练初期，学习率从一个较低的值逐渐增加到设定的初始学习率。这有助于模型在训练初期稳定下来，防止初始学习率过高导致的不稳定。
- **周期性重启**：学习率按周期性地增加和减少，每次“重启”都从较高的学习率开始，然后再次衰减。这种方法有助于模型跳出局部最小值，寻找更好的全局最小值。

这些学习率调整方法可以单独使用，也可以结合使用，以达到最佳的训练效果。选择哪种衰减策略取决于具体任务、模型的复杂性以及训练数据的特点。在实际应用中，通常需要通过多次实验来确定最合适的学习率调整策略。

<h1 id="11什么是方向导数">11.什么是方向导数</h1>

- 导数是二维平面中，曲线上某一点沿着x轴方向变化的速率
- 偏导数是在三维空间中，曲面上某一点沿着x轴方向或y轴方向变化的速率
- 方向导数是在三维空间中，曲面上某一点沿着任一方向的变化率

定理：如果函数 $f(x,y)$ 在点 $P_{0}\left(x_{0}, y_{0}\right)$ 可微分,那么函数在该点沿任一方向 $l$ 的方向导数存在,且有

$$\frac{\partial f}{\partial \vec{l}}=\frac{\partial f}{\partial x} \cdot \cos \alpha+\frac{\partial f}{\partial y} \cdot \cos \beta$其中$\vec{l}=\{\cos \alpha, \cos \beta\}$$

<h1 id="12什么是梯度">12.什么是梯度</h1>

设函数 $z=f(x,y)$ 在平面区域$D$内具有一阶连续偏导数，对于区域$D$中的每一个点都可以确定一个向量 $f_{x}(x, y) \vec{i}+f_{y}(x, y) \vec{j}$ 成为函数在该点的梯度，记为：

$$\text{gradf}(\mathrm{x}, \mathrm{y})=\nabla f(x, y)= \frac{\partial f}{\partial x}, \frac{\partial f}{\partial y} = f_{x}(x, y) \vec{i}+f_{y}(x, y) \vec{j}$$

<h1 id="13为什么沿梯度方向是函数变化最快的方向？">13.为什么沿梯度方向是函数变化最快的方向？</h1>

梯度下降法，是机器学习、深度学习中比较核心也是较为常用的优化算法，但为什么沿梯度方向，函数变化最快？方向导数与梯度有什么关系？

设 $\vec{e}=\{\cos \alpha, \cos \beta\}$ 是方向 $l$ 上的单位向量，则

$$\frac{\partial f}{\partial \vec{l}}=\frac{\partial f}{\partial x} \cdot \cos \alpha+\frac{\partial f}{\partial y} \cdot \cos \beta = \frac{\partial f}{\partial x}, \frac{\partial f}{\partial y} {\cos \alpha, \cos \beta\}=\text{grad} f(x, y) \cdot \vec{e}$$

$=|\text{gradf}(x, y)|\cdot\cos\theta$ ，其中 $\theta$ 为 $\text{gradf}(\mathrm{x}, \mathrm{y})$ 与 $\vec{e}$ 的夹角

1. 当 $\theta =0$ 时，即 $\vec{e}$ 沿着梯度方向，方向导数取得最大值
2. 当 $\theta = \pi/2$ 时，方向导数为0
3. 当 $\theta =\pi$ 时，即 $\vec{e}$ 沿着梯度反方向，方向导数取得最小值
## 综上
当方向导数大于0时，方向导数的大小用来描述函数上升的速率快慢，方向导数越大，表明函数上升越快，当方向导数小于0时，方向导数的大小用来描述函数下降的速率快慢，方向导数越小，表明函数下降越快，即 $\vec{e}$ 沿着梯度反方向，方向导数取得最小值，此时函数下降速率最快。
