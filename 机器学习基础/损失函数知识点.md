# 目录

- [1.Softmax的定义和作用](#user-content-1.softmax的定义和作用)
- [2.交叉熵定义和作用](#user-content-2.交叉熵定义和作用)
- [3.格拉姆矩阵的相关概念？](#user-content-3.格拉姆矩阵的相关概念？)
- [4.感知损失的相关概念?](#user-content-4.感知损失的相关概念)
- [5.KL散度相关概念](#user-content-5.kl散度相关概念)
- [6.JS散度相关概念](#user-content-6.js散度相关概念)
- [7.什么是机器学习中的局部最优与全局最优？](#user-content-7.什么是机器学习中的局部最优与全局最优？)
- [8.介绍一下机器学习中的目标函数、代价函数和损失函数的概念](#user-content-8.介绍一下机器学习中的目标函数、代价函数和损失函数的概念)
- [9.常用的距离度量方法](#user-content-9.常用的距离度量方法)


<h2 id="1.softmax的定义和作用">1.Softmax的定义和作用</h2>
  
在二分类问题中，我们可以使用sigmoid函数将输出映射到【0，1】区间中，从而得到单个类别的概率。当我们将问题推广到多分类问题时，可以使用Softmax函数，对输出的值映射为概率值。
  
![](https://files.mdnice.com/user/33499/ba15fa57-2ef3-4a47-9536-4bc277428f01.png)

其定义为：

![](https://files.mdnice.com/user/33499/526a9221-7dae-4f45-99ae-7d9f77dc3aa3.png)

其中a代表了模型的输出。

<h2 id="2.交叉熵定义和作用">2.交叉熵定义和作用</h2>

交叉熵（cross entropy）常用于深度学习中的分类任务，其可以表示预测值与ground truth之间的差距。

交叉熵是信息论中的概念。其定义为：
  
![](https://files.mdnice.com/user/33499/7c811f76-ef47-42b9-93b2-25517e7463ed.png)

$P$ 代表 $gt$ 的概率分布， $q$ 代表预测值的概率分布。交叉熵从相对熵（KL散度）演变而来， $log$ 代表了信息量， $q$ 越大说明可能性越大，其信息量越少；反之则信息量越大。通过不断的训练优化，逐步减小交叉熵损失函数的值来达到缩小 $p$ 和 $q$ 距离的目的。


<h2 id="3.格拉姆矩阵的相关概念？">3.格拉姆矩阵的相关概念？</h2>

n维欧式空间中任意k个向量之间两两的内积所组成的矩阵，称为这k个向量的格拉姆矩阵(Gram matrix)，这是一个对称矩阵。 

![](https://files.mdnice.com/user/33499/a850fa8d-7ae5-415d-89ad-230836e01a49.png)

![](https://files.mdnice.com/user/33499/08889876-98b7-4a2f-ad50-7ea4eb7128a7.png)

其中对角线元素提供了k个不同特征图（a1，a2 ... ，ak）各自的信息，其余元素提供了不同特征图之间的相关信息。既能体现出有哪些特征，又能体现出不同特征间的紧密程度。图像风格迁移领域将其定义为风格特征。

格拉姆矩阵在风格迁移中有广泛的应用，深度学习中经典的风格迁移流程是：

1. 准备基线图像和风格图像。

2. 使用特征提取器分别提取基线图像和风格图像的feature map。

3. 分别计算两个图像的feature map的格拉姆矩阵，以两个图像的格拉姆矩阵的差异最小化为优化目标，不断调整基线图像，使风格不断接近目标风格图像。

<h2 id="4.感知损失的相关概念">4.感知损失的相关概念?</h2>

感知损失在图像生成领域中比较常用。其核心是将gt图片卷积得到的高层feature与生成图片卷积得到的高层feature进行回归，从而约束生成图像的高层特征（内容和全局结构）。

![经典感知损失结构](https://files.mdnice.com/user/33499/2c510820-c674-4e92-bd10-a742f1d1218f.png)

上面的公式中，划线部分代表了高层特征，一般使用VGG作为特征提取器。

<h2 id="5.kl散度相关概念">5.KL散度相关概念</h2>

KL散度（Kullback-Leibler divergence），可以以称作相对熵（relative entropy）或信息散度（information divergence）。<font color=DeepSkyBlue>KL散度的理论意义在于度量两个概率分布之间的差异程度，当KL散度越大的时候，说明两者的差异程度越大；而当KL散度小的时候，则说明两者的差异程度小</font>。如果两者相同的话，则该KL散度应该为0。

接下来我们举一个具体的🌰：

我们设定两个概率分布分别为 $P$ 和 $Q$ ，在设定为连续随机变量的前提下，他们对应的概率密度函数分别为 $p(x)$ 和 $q(x)$ 。如果我们用 $q(x)$ 去近似 $p(x)$ ，则KL散度可以表示为：

$$KL(P||Q) = \int p(x)\log \frac{p(x)}{q(x)}dx $$

从上面的公式可以看出，当且仅当 $P=Q$ 时， $KL(P||Q) = 0$ 。此外我们可以知道<font color=DeepSkyBlue>KL散度具备非负性</font>，即 $KL(P||Q) >= 0$ 。并且从公式中我们也发现，<font color=DeepSkyBlue>KL散度不具备对称性</font>，也就是说 $P$ 对于 $Q$ 的KL散度并不等于 $Q$ 对于 $P$ 的KL散度。因此，**KL散度并不是一个度量（metric），即KL散度并非距离**。

我们再来看看离散的情况下用 $q(x)$ 去近似 $p(x)$ 的KL散度的公式：

$$KL(P||Q) = \sum p(x)\log \frac{p(x)}{q(x)} $$

接下来我们对上面的式子进行展开：

$$KL(P||Q) = \sum p(x)\log \frac{p(x)}{q(x)}  = -\sum p(x)\log(q(x)) + \sum p(x)\log(p(x)) = H(P,Q) - H(P)$$

最后得到的第一项称作 $P$ 和 $Q$ 的交叉熵（cross entropy），后面一项就是熵。

在信息论中，熵代表着信息量， $H(P)$ 代表着基于 $P$ 分布自身的编码长度，也就是最优的编码长度（最小字节数）。而 $H(P,Q)$ 则代表着用 $Q$ 的分布去近似 $P$ 分布的信息，自然需要更多的编码长度。并且两个分布差异越大，需要的编码长度越大。所以两个值相减是大于等于0的一个值，代表冗余的编码长度，也就是两个分布差异的程度。所以<font color=DeepSkyBlue>KL散度在信息论中还可以称为相对熵（relative entropy）</font>。

对深度学习中的生成模型来说，我们希望最小化真实数据分布与生成数据分布之间的KL散度，从而使得生成数据尽可能接近真实数据的分布。在实际场景中，我们是几乎不可能知道真实数据分布 $P_{data}(x)$ 的，我们使用训练数据形成的生成分布在逼近 $P_{data}(x)$ 。

<h2 id="6.js散度相关概念">6.JS散度相关概念</h2>

JS散度全称Jensen-Shannon散度，简称JS散度。在概率统计中，<font color=DeepSkyBlue>JS散度也与KL散度一样具备了测量两个概率分布相似程度的能力，它的计算方法基于KL散度，继承了KL散度的非负性等，但有一点重要的不同，JS散度具备了对称性</font>。

JS散度的公式如下所示，我们设定两个概率分布为 $P$ 和 $Q$ ，另外我们还设定 $M = 0.5 \times (P + Q)$ ，KL为KL散度公式。

$$JSD(P||Q) = \frac{1}{2}KL(P||M) + \frac{1}{2}KL(Q||M) $$

如果我们把KL散度公式写入展开的话，结果如下所示：

$$JSD(P||Q) = \int p(x)\log \frac{p(x)}{\frac{p(x) +q(x)}{2}} dx+ \int q(x)\log \frac{q(x)}{\frac{p(x) +q(x)}{2}}dx$$

深度学习中使用KL散度和JS散度进行度量的时候存在一个问题：

如果两个分布 $P$ ， $Q$ 离得很远，完全没有重叠的时候，那么KL散度值是没有意义的，而JS散度值是一个常数 $\log2$ 。这对以梯度下降为基础的深度学习算法有很大影响，这意味梯度为0，即梯度消失。

<h2 id="7.什么是机器学习中的局部最优与全局最优？">7.什么是机器学习中的局部最优与全局最优？</h2>

在机器学习中，特别是在训练各种类型的模型时，局部最优和全局最优的概念是理解模型优化过程的关键部分。这些概念与模型的目标函数或损失函数的优化密切相关。

### 目标函数或损失函数

首先，让我们了解机器学习模型中用于训练的基本元素之一：**目标函数**或**损失函数**。简单来说，这是一个数学函数，用于衡量模型预测的好坏。训练模型的过程实质上是一个优化问题，目的是找到最小化（或最大化，取决于问题）这个函数的参数设置。

### 全局最优

**全局最优**是指目标函数的最优解，无论从函数的哪个点出发，这个解都是最佳的。在全局最优点，目标函数达到其可能的最小值（对于最小化问题）或最大值（对于最大化问题）。这意味着没有其他可行的参数值能使得损失函数的值比在全局最优点更小（或更大）。

### 局部最优

与全局最优相对的是**局部最优**。在局部最优点，目标函数的值比其相邻点更优，但可能不如其他远离该点的值。简单来说，局部最优点在其周围的小区域内是最优的，但在整个参数空间中不一定是最优的。在高维空间中，局部最优可能非常频繁，特别是在复杂的模型如深度学习模型中。

### 生动例子

柏拉图有一天向他的老师苏格拉底提出了一个问题：“什么是爱情？”苏格拉底让他走进一片麦田，从中挑选出最大的一颗麦穗带回来，但规定他在选择过程中不得回头，且只能摘取一次。结果柏拉图空手而归，他解释说，虽然途中见到了不少不错的麦穗，但总想是否还有更好的，结果一路走到了尽头，才发现早先见到的麦穗是更好的。于是他选择了放弃。苏格拉底对他说：“这就是爱情。”

这个故事启示我们，由于**生命的有限性和不确定性，寻找全局最优解非常困难，甚至可以说根本不存在**。我们应该设定一些限制条件，在这些条件下寻找最优解，即局部最优解。有所收获总比空手而归好，哪怕这种收获仅仅是一次有趣的经历。

柏拉图又一次询问苏格拉底：“什么是婚姻？”这一次，苏格拉底让他走进一片树林，挑选一棵最好的树作为圣诞树，同样规定不能回头，只能选择一次。这次，柏拉图带着疲惫的身躯挑选了一棵看起来直挺且翠绿但稍显稀疏的杉树，他解释说，吸取了之前的教训，当他看到一棵看似不错的树时，意识到时间和体力都快不够用了，便不再迟疑，不管它是否是最好的，就将它带了回来。苏格拉底对他说：“这就是婚姻。”

### 总结

理解局部最优和全局最优在机器学习中的作用对于设计和调整模型至关重要。尽管寻找全局最优可能在某些情况下非常困难甚至不可行，通过适当的策略和技术，可以有效地缓解局部最优的限制，提高模型的整体性能。


<h2 id="8.介绍一下机器学习中的目标函数、代价函数和损失函数的概念">8.介绍一下机器学习中的目标函数、代价函数和损失函数的概念</h2>

在机器学习中，目标函数（Objective Function）、代价函数（Cost Function）和损失函数（Loss Function）是几个非常重要的概念。

- **损失函数（Loss Function）**：评估单个样本的误差，是模型预测与真实值之间差异的度量。
- **代价函数（Cost Function）**：评估整个模型在所有训练样本上的整体误差，是所有损失函数的平均值或总和。
- **目标函数（Objective Function）**：包括代价函数和其他优化目标（如正则化项），指导模型的整体优化过程。

### 1. 损失函数（Loss Function）

#### 定义

损失函数用于衡量单个训练样本的预测值与真实值之间的误差。它度量了模型对单个样本的预测效果。

#### 数学表示

对于一个单一训练样本 $(x_i, y_i)$ ，其损失函数 $L_i(\theta)$ 可以表示为：

$$L_i(\theta) = L(h_\theta(x_i), y_i)$$

其中：
- $h_\theta(x_i)$ 是模型的预测值。
- $y_i$ 是样本的真实值。
- $L$ 是用于度量预测值和真实值差异的损失函数。

#### 常见损失函数

1. **均方误差（Mean Squared Error, MSE）**：

$$L_i(\theta) = (h_\theta(x_i) - y_i)^2$$

2. **对数损失（Log Loss）**：

$$L_i(\theta) = -[y_i \log(h_\theta(x_i)) + (1 - y_i) \log(1 - h_\theta(x_i))]$$

3. **绝对误差（Mean Absolute Error, MAE）**：

$$L_i(\theta) = |h_\theta(x_i) - y_i|$$

### 2. 代价函数（Cost Function）

#### 定义

代价函数是一个整体的度量，用于评估整个模型的性能。它通常是所有训练样本的损失的平均值或总和。代价函数反映了模型在所有训练数据上的整体表现。

#### 数学表示

假设我们有一个包含 $N$ 个样本的数据集，每个样本的损失函数为 $L_i$ 。那么代价函数 $J(\theta)$ 可以表示为：

$$J(\theta) = \frac{1}{N} \sum_{i=1}^{N} L_i(\theta)$$

其中：
- $\theta$ 表示模型的参数。
- $L_i(\theta)$ 是第 $i$ 个样本的损失函数。

#### 作用

代价函数用于评估整个模型在训练集上的整体误差，并作为优化算法的目标。模型训练的目标是通过调整参数 $\theta$ 来最小化代价函数 $J(\theta)$ 。

### 3. 目标函数（Objective Function）

#### 定义

目标函数是一个更广义的概念，它不仅包括代价函数，还可以包括正则化项或其他需要优化的目标。目标函数的目的是指导模型的优化过程，**确保模型不仅在训练集上表现良好，还具备良好的泛化能力**。

#### 数学表示

目标函数可以表示为代价函数和正则化项的组合：

$$\text{Objective Function} = J(\theta) + \lambda R(\theta)$$

其中：
- $J(\theta)$ 是代价函数。
- $\lambda$ 是正则化系数，用于控制正则化项的影响。
- $R(\theta)$ 是正则化项，用于防止过拟合。

#### 作用

目标函数用于指导模型的整体优化过程。通过最小化目标函数，可以确保模型在训练数据和新数据上都表现良好。

### 三者的关系与区别

1. **损失函数（Loss Function）**：
   - 衡量单个样本的误差。
   - 是代价函数的组成部分。

2. **代价函数（Cost Function）**：
   - 衡量所有训练样本的整体误差（通常是损失函数的平均值或总和）。
   - 用于评估模型的整体性能。

3. **目标函数（Objective Function）**：
   - 包括代价函数和其他优化目标（如正则化项）。
   - 指导模型的整体优化过程。

### 通俗易懂的示例讲解

假设我们有一个线性回归模型，目标是预测房价。数据集包含三个样本，每个样本的损失函数为均方误差（MSE）。具体如下：

- 样本1：真实房价 $y_1 = 300,000$ ，预测房价 $\hat{y}_1 = 310,000$
- 样本2：真实房价 $y_2 = 400,000$ ，预测房价 $\hat{y}_2 = 390,000$
- 样本3：真实房价 $y_3 = 500,000$ ，预测房价 $\hat{y}_3 = 510,000$

计算每个样本的损失函数：

$$L_1 = (310,000 - 300,000)^2 = 100,000,000$$
$$L_2 = (390,000 - 400,000)^2 = 100,000,000$$
$$L_3 = (510,000 - 500,000)^2 = 100,000,000$$

计算代价函数（均方误差的平均值）：

$$J(\theta) = \frac{1}{3} (L_1 + L_2 + L_3) = \frac{1}{3} (100,000,000 + 100,000,000 + 100,000,000) = 100,000,000$$

假设我们加上L2正则化项，正则化项 $R(\theta)$ 计算如下：

$$R(\theta) = \lambda \sum_{j=1}^{m} \theta_j^2$$

最终目标函数为：

$$\text{Objective Function} = J(\theta) + \lambda R(\theta)$$


<h2 id="9.常用的距离度量方法">9.常用的距离度量方法</h2>

1. 欧式距离

2. 闵可夫斯基距离

3. 马氏距离

4. 互信息

5. 余弦距离

6. 皮尔逊相关系数

7. Jaccard相关系数

8. 曼哈顿距离
  
![](https://files.mdnice.com/user/33499/d17199ff-84e7-49e1-bbf5-19a2b12e6686.png)
