# 目录

 - [【一】什么是模型的偏差和方差？](#user-content-【一】什么是模型的偏差和方差？)
 - [【二】训练集/验证集/测试集划分](#user-content-【二】训练集验证集测试集划分)

<h2 id="【一】什么是模型的偏差和方差？">【一】什么是模型的偏差和方差？</h2>
  
误差（Error）= 偏差（Bias） + 方差（Variance） + 噪声（Noise），一般地，我们把机器学习模型的预测输出与样本的真实label之间的差异称为误差，其反应的是整个模型的准确度。

噪声（Noise）：描述了在当前任务上任何机器学习算法所能达到的<font color=DeepSkyBlue>期望泛化误差的下界</font>，即刻画了当前任务本质的难度。

偏差（Bias）：衡量了模型拟合训练数据的能力，偏差反应的是所有采样得到的大小相同的训练集训练出的所有模型的输出平均值和真实label之间的偏差，即模型本身的精确度。

偏差通常是由于我们对机器学习算法做了错误的假设所导致的，比如真实数据分布映射的是某个二次函数，但我们假设模型是一次函数。

<font color=DeepSkyBlue>偏差（Bias）越小，拟合能力却强（可能产生过拟合）；反之，拟合能力越弱（可能产生欠拟合）</font>。偏差越大，越偏离真实数据。

方差描述的是预测值的变化范围，离散程度，也就是离期望值的距离。<font color=DeepSkyBlue>方差越大，数据的分布越分散，模型的稳定程度越差</font>。

方差也反应了模型每一次输出结果与模型输出期望之间的误差，即模型的稳定性。<font color=DeepSkyBlue>由方差带来的误差通常体现在测试误差相对于训练误差的增量上</font>。

方差通常是由于模型的复杂度相对于训练样本数过高导致的。<font color=DeepSkyBlue>方差越小，模型的泛化能力越高；反之，模型的泛化能力越低</font>。

<h2 id="【二】训练集验证集测试集划分">【二】训练集/验证集/测试集划分</h2>
  
机器学习的直接目的是希望模型在真实场景的数据上有很好的预测效果，泛化误差越低越好。

如何去跟踪泛化误差呢？这时就需要验证集和测试集了。

我们可以使用训练集的数据来训练模型，然后用测试集上的误差推测最终模型在应对现实场景中的泛化误差。有了测试集，我们可以在本地验证模型的最终的近似效果。

与此同时，我们在模型训练过程中要实时监控模型的指标情况，从而进行模型参数优选操作。验证集就用于模型训练过程中的指标评估。

一般来说，如果当数据量不是很大的情况（万级别以下）可以将训练集、验证集和测试集划分为<font color=DeepSkyBlue>6：2：2</font>；如果是万级别甚至十万级别的数据量，可以将训练集、验证集和测试集比例调整为<font color=DeepSkyBlue>98：1：1</font>。

（注：在数据集划分时要主要类别的平衡）

如果模型在训练集上拟合效果比较优秀，但是在测试集上拟合效果比较差，则表示方差较大，说明模型的稳定程度较差，出现这种现象可能是由于模型对训练集过拟合造成的。

接下来我们用下面的射击的例子进一步解释这二者的区别。假设一次射击就是机器学习模型对一个样本进行预测。射中靶心位置代表预测准确，偏离靶心越远代表预测误差越大，其中左上角是最好的结果。

![](https://files.mdnice.com/user/33499/e6a5dec3-92c5-44c9-a37c-9ea882b71c7c.png)
